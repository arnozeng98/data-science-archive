
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Blogs &#8212; Arno&#39;s Projects Collection</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'archive/blogs';</script>
    <link rel="canonical" href="docs.arnozeng.com/archive/blogs.html" />
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="CFG Parsers" href="cfg-parsers.html" />
    <link rel="prev" title="Coronary Heart Disease Study" href="coronary-heart-disease-study.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Arno's Projects Collection - Home"/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt="Arno's Projects Collection - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Arno’s Projects Collection
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="house-prices%28py%29.html">House Prices (Python)</a></li>
<li class="toctree-l1"><a class="reference internal" href="house-prices%28r%29.html">House Prices (R)</a></li>
<li class="toctree-l1"><a class="reference internal" href="coronary-heart-disease-study.html">Coronary Heart Disease Study</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Blogs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">NLP</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="cfg-parsers.html">CFG Parsers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Database</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="postgresql.html">PostgreSQL</a></li>
<li class="toctree-l1"><a class="reference internal" href="mongodb.html">MongoDB</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Visualization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="visualization.html">Visualization</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/arnozeng98/data-science-archive" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/arnozeng98/data-science-archive/issues/new?title=Issue%20on%20page%20%2Farchive/blogs.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/archive/blogs.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Blogs</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assignment-objectives">Assignment Objectives</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-does-this-relate-to-what-we-re-doing-in-class">How does this relate to what we’re doing in class?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-started">Getting Started</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tidy-submission">Tidy Submission</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-0-prepare-the-corpus">Part 0: Prepare the corpus</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#assignment-0-1">Assignment 0.1</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-clustering-with-dimensionality-reduced-vectors">Part 1: Clustering with dimensionality reduced vectors</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">1.1</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">1.2</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">1.3</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#optional">1.4 (Optional)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">1.5 (Optional)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">1.6</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">1.7</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">1.8</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">1.9</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-topic-modelling">Part 2: Topic modelling</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">2.1</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">2.2</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">2.3</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">2.4</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">2.5 (Optional)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">2.6 (Optional)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-report">Exercise 3: Report</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="blogs">
<h1>Blogs<a class="headerlink" href="#blogs" title="Link to this heading">#</a></h1>
<section id="assignment-objectives">
<h2>Assignment Objectives<a class="headerlink" href="#assignment-objectives" title="Link to this heading">#</a></h2>
<p>In this assignment you will</p>
<ul class="simple">
<li><p>Convert a unlabeled blog corpus into a BOW representation</p></li>
<li><p>Test whether dimensionality reduction with SVD preserves corpus variation in the context of clustering</p></li>
<li><p>Explore the corpus using the topics produced by an LDA topic model</p></li>
</ul>
<section id="how-does-this-relate-to-what-we-re-doing-in-class">
<h3>How does this relate to what we’re doing in class?<a class="headerlink" href="#how-does-this-relate-to-what-we-re-doing-in-class" title="Link to this heading">#</a></h3>
<p>On Monday, we took a look at how we can represent a document with a bag-of-words representation, and how that doesn’t really capture document similarities.  Part 1 will have you create a bag of words representation, and then condense it using SVD, performing clustering on the resulting vectors.</p>
<p>On Wednesday, we will look at Latent Dirichlet Allocation as a way of clustering documents without an intermediate vector representation.  Part 2 has you create an LDA model for the same dataset you ran SVD on, so that you can compare and contrast the results.</p>
</section>
</section>
<section id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Link to this heading">#</a></h2>
<p>Run the code below to access relevant modules (you can add to this as needed)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">zscore</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">MiniBatchKMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">adjusted_rand_score</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">TruncatedSVD</span><span class="p">,</span><span class="n">LatentDirichletAllocation</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">normalize</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">seed</span>

<span class="c1"># Reproducibility</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="tidy-submission">
<h2>Tidy Submission<a class="headerlink" href="#tidy-submission" title="Link to this heading">#</a></h2>
<p>rubric={mechanics:1}</p>
<p>To get the marks for tidy submission:</p>
<ul class="simple">
<li><p>Submit the assignment by filling in this jupyter notebook with your answers embedded</p></li>
<li><p>Be sure to follow the <a class="reference external" href="https://ubc-mds.github.io/resources_pages/general_lab_instructions">general lab instructions</a></p></li>
<li><p>Except you should not put the data in your lab repo, instead define the <code class="docutils literal notranslate"><span class="pre">path_to_data</span></code> below</p></li>
<li><p>This is a <em>paired lab</em> - you should complete this lab with a partner (a small number of 3-person teams is also ok).</p></li>
</ul>
<section id="part-0-prepare-the-corpus">
<h3>Part 0: Prepare the corpus<a class="headerlink" href="#part-0-prepare-the-corpus" title="Link to this heading">#</a></h3>
<section id="assignment-0-1">
<h4>Assignment 0.1<a class="headerlink" href="#assignment-0-1" title="Link to this heading">#</a></h4>
<p>rubric={accuracy:3,efficiency:1, quality:1}</p>
<p>A zipped text file containing 8752 blog posts that we will use for this lab is provided in the data directory <a class="reference external" href="https://github.ubc.ca/MDS-CL-2024-25/DSCI_563_unsup-learn_students/tree/master/data/blogposts.zip">here</a>. Download the zip-file but <strong>don’t push the data to github</strong> (when grading your lab, the TA will otherwise end up with hundreds of megabytes of unwanted data, when pulling all the student repos). Update the <code class="docutils literal notranslate"><span class="pre">PATH_TO_DATA</span></code> variable below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PATH_TO_DATA</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;blogposts.zip&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>In order to read the data, you should initialize a <code class="docutils literal notranslate"><span class="pre">ZipFile</span></code> object provided in the <a class="reference internal" href="#"><span class="xref myst">zipfile</span></a> module. You should first initialize a <code class="docutils literal notranslate"><span class="pre">ZipFile</span></code> object for the <code class="docutils literal notranslate"><span class="pre">blogposts.zip</span></code>. You can then use the member function <code class="docutils literal notranslate"><span class="pre">ZipFile.open()</span></code> to open the file <code class="docutils literal notranslate"><span class="pre">blogposts.txt</span></code> which is part of the zip archive <code class="docutils literal notranslate"><span class="pre">blogposts.zip</span></code>. You can then the the data in the usual way using the <code class="docutils literal notranslate"><span class="pre">read()</span></code> member function of the file object.</p>
<p><strong>Note</strong> that <code class="docutils literal notranslate"><span class="pre">read()</span></code> will return a <code class="docutils literal notranslate"><span class="pre">bytes</span></code> object, not a string. You will need to <a class="reference external" href="https://stackabuse.com/convert-bytes-to-string-in-python/">decode</a> the data into <code class="docutils literal notranslate"><span class="pre">utf-8</span></code>. Since the data in <code class="docutils literal notranslate"><span class="pre">blogposts.txt</span></code> is not entirely clean, you will need to use the option <code class="docutils literal notranslate"><span class="pre">errors=&quot;ignore&quot;</span></code>, when decoding. Otherwise, you’ll get a <code class="docutils literal notranslate"><span class="pre">UnicodeDecodeError</span></code> error.</p>
<p>Store the text in the file into a variable <code class="docutils literal notranslate"><span class="pre">data</span></code>.</p>
<p>After reading the data, you should convert it into a scipy sparse matrix format (i.e. the output of Scikit Learn vectorizers - see practical work 5) where each row is a text and each column the count of words in the corpus. Each post is enclosed in an XML <code class="docutils literal notranslate"><span class="pre">&lt;post&gt;</span></code> tag which should not be included. For efficiency and quality, we strongly recommend you extract the individual text strings corresponding to each text using <code class="docutils literal notranslate"><span class="pre">re.finditer</span></code> and <code class="docutils literal notranslate"><span class="pre">MatchObject.group</span></code> methods.  As with all regexes, it’s fine to take a look at the data before creating the regex - see what you’re actually working with!</p>
<p>Your final representation vectors should:</p>
<ul class="simple">
<li><p>Be a bag of words</p></li>
<li><p>Be all lowercase</p></li>
<li><p>Have no punctuation</p></li>
<li><p>Have no words that appear in fewer than 10 different texts</p></li>
<li><p>Have no words that appear in more than 20% of the texts</p></li>
</ul>
<p>The Scikit-learn <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">CountVectorizer</a> is a good choice for doing this (it has options for all of the above), though you don’t have to use it if you prefer to do something else.</p>
<p>Store your vectorized blog posts as a matrix <code class="docutils literal notranslate"><span class="pre">post_X</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reading the data from the zip file</span>
<span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">PATH_TO_DATA</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zf</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">zf</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;blogposts.txt&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Adjusting the regex to handle potential whitespace and newlines in &lt;post&gt; tags</span>
<span class="n">posts</span> <span class="o">=</span> <span class="p">[</span><span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">finditer</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;&lt;post.*?&gt;(.*?)&lt;/post&gt;&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)]</span>

<span class="c1"># Check the first few extracted posts to ensure the regex works now</span>
<span class="n">posts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;\r\n\r\n\t \r\n      I recently lost my job. I sort of wanted to lose it actually. Kind of like a relationship that no longer works. Im looking for a job now that doesnt involve much responsibility. too bad the nearest hot topics is at least 2 hours away. I wouldnt have to dress up for the job interview. when no one else is at home I like to play &quot;setting sun&quot; by the chemical brothers thru one blown speaker really loud while I perfect my robot dance. it keeps my neighbours on theyre toes. Im convinced one of my neighbours is actually a pirate.he has a beard,swords and exotic birds.he\&#39;s an eyepatch away from pillaging the neighbourhood. I special ordered my monochrome black chuck taylor hi-tops, for job interviews and work.hard to find vegan work shoes. my new favorite band is The Shins, but Oh Inverted World! era, I didnt like Chutes Too Narrow as much as the critics. its BeachBoys-esque in a an updated indie rock way, Like another favorite band of mine, Dios. I started cutting my own hair again (and dying it heavy Blue-Black). recent purchases: violent femmes-rock!!! best of elvis costello Belly-sun ep PJ Harvey-rid of me romeo and julliet movie soundtrack rock music: a tribute to weezer (I got the dvd and I still need to get the blue album deluxe edition) Ozma-spending time on the Borderline Rufio-EP The Smiths-best of volume 2  next time Im going to write a thesis on the lyrical conten of the Sugarcubes &quot;lifes too good&quot; album. Gotta see The new Pixies DVD cant wait for the jandek film to come out on DVD too! (I played dome jandek this morning for my sis and her husband.he compared it to Jim Morrison\&#39;s poetry albums!)  oh and the pictures. the black-haired young man in the reggie and the full effect t shirt is of course me, and the little girl washing dishes is my niece when she was about 3. I love that pic, you can read into it on so many different levels. a heavily photoshopped version is going to be used in flyers and as a single sleeve. and the pic of me was taken in riverside CA in a motel before the NOFX show and before the Absinthe started to kick in. thats Joe X. seated behind me and an Absinthe bottle by my hand. marta,please send some raNdom pics for me to put on here.\r\n     \r\n\r\n    \r\n&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Preprocessing the extracted posts: removing extra whitespace, newlines, and leading/trailing spaces</span>
<span class="n">cleaned_posts</span> <span class="o">=</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">post</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">post</span> <span class="ow">in</span> <span class="n">posts</span><span class="p">]</span>

<span class="c1"># Checking the first few cleaned posts to verify preprocessing</span>
<span class="n">cleaned_posts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;I recently lost my job. I sort of wanted to lose it actually. Kind of like a relationship that no longer works. Im looking for a job now that doesnt involve much responsibility. too bad the nearest hot topics is at least 2 hours away. I wouldnt have to dress up for the job interview. when no one else is at home I like to play &quot;setting sun&quot; by the chemical brothers thru one blown speaker really loud while I perfect my robot dance. it keeps my neighbours on theyre toes. Im convinced one of my neighbours is actually a pirate.he has a beard,swords and exotic birds.he\&#39;s an eyepatch away from pillaging the neighbourhood. I special ordered my monochrome black chuck taylor hi-tops, for job interviews and work.hard to find vegan work shoes. my new favorite band is The Shins, but Oh Inverted World! era, I didnt like Chutes Too Narrow as much as the critics. its BeachBoys-esque in a an updated indie rock way, Like another favorite band of mine, Dios. I started cutting my own hair again (and dying it heavy Blue-Black). recent purchases: violent femmes-rock!!! best of elvis costello Belly-sun ep PJ Harvey-rid of me romeo and julliet movie soundtrack rock music: a tribute to weezer (I got the dvd and I still need to get the blue album deluxe edition) Ozma-spending time on the Borderline Rufio-EP The Smiths-best of volume 2 next time Im going to write a thesis on the lyrical conten of the Sugarcubes &quot;lifes too good&quot; album. Gotta see The new Pixies DVD cant wait for the jandek film to come out on DVD too! (I played dome jandek this morning for my sis and her husband.he compared it to Jim Morrison\&#39;s poetry albums!) oh and the pictures. the black-haired young man in the reggie and the full effect t shirt is of course me, and the little girl washing dishes is my niece when she was about 3. I love that pic, you can read into it on so many different levels. a heavily photoshopped version is going to be used in flyers and as a single sleeve. and the pic of me was taken in riverside CA in a motel before the NOFX show and before the Absinthe started to kick in. thats Joe X. seated behind me and an Absinthe bottle by my hand. marta,please send some raNdom pics for me to put on here.&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="c1"># your code here</span>

<span class="c1"># Vectorizing the cleaned posts</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span>
    <span class="n">lowercase</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">token_pattern</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;\b\w+\b&#39;</span><span class="p">,</span>  <span class="c1"># Match words only</span>
    <span class="n">min_df</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="c1"># Appear in at least 10 texts</span>
    <span class="n">max_df</span><span class="o">=</span><span class="mf">0.2</span>  <span class="c1"># Appear in at most 20% of texts</span>
<span class="p">)</span>

<span class="c1"># Fitting and transforming the data to a sparse matrix</span>
<span class="n">post_X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cleaned_posts</span><span class="p">)</span>

<span class="c1"># Output the shape of the resulting sparse matrix</span>
<span class="n">post_X</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(8752, 14939)
</pre></div>
</div>
</div>
</div>
<p>Print out the shape of your matrix when you’re done. You should end up with a sparse matrix with 8752 rows and about 14911 columns (it is okay if the second number is not exactly the same, but it should be close!):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">post_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">8752</span>
<span class="k">assert</span> <span class="mi">14000</span> <span class="o">&lt;</span> <span class="n">post_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">and</span> <span class="n">post_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">15000</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Success&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Success
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="part-1-clustering-with-dimensionality-reduced-vectors">
<h3>Part 1: Clustering with dimensionality reduced vectors<a class="headerlink" href="#part-1-clustering-with-dimensionality-reduced-vectors" title="Link to this heading">#</a></h3>
<section id="id1">
<h4>1.1<a class="headerlink" href="#id1" title="Link to this heading">#</a></h4>
<p>rubric={accuracy:1}</p>
<p>L2 normalize the matrix <code class="docutils literal notranslate"><span class="pre">post_X</span></code> from Exercise 1 using <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html"><code class="docutils literal notranslate"><span class="pre">sklearn.preprocessing.normalize</span></code></a>. Make sure that you are normalizing w.r.t. to the correct axis. <strong>Hint</strong> there are 8752 blog posts.</p>
<p>You should preserve the original count matrix for later, so don’t overwrite it. Instead store the normalized matrix as <code class="docutils literal notranslate"><span class="pre">post_X_norm</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">normalize</span>

<span class="c1"># your code here</span>
<span class="c1"># use  `normalize` using `post_X`; </span>

<span class="c1"># L2 normalize the matrix along the rows (axis=1)</span>
<span class="n">post_X_norm</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">post_X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">post_X_norm</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(8752, 14939)
</pre></div>
</div>
</div>
</div>
<p>Assertion to check your code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">post_X_norm</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># --&gt; sparse matrix </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Compressed Sparse Row sparse matrix of dtype &#39;float64&#39;
	with 146 stored elements and shape (1, 14939)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># NOTE: a.toarray() or a.A </span>
<span class="n">post_X_norm</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>  <span class="c1"># --&gt; array([[0., 0., 0., ..., 0., 0., 0.]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0., 0., 0., ..., 0., 0., 0.]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">post_X_norm</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>  <span class="c1"># --&gt; return l2 norm by default</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.9999999999999999)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">post_X_norm</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.0001</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Success!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Success!
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h4>1.2<a class="headerlink" href="#id2" title="Link to this heading">#</a></h4>
<p>rubric={accuracy:2,viz:1}</p>
<p>Next, use the elbow method to identify a good <em>k</em> to cluster your blog data using k-means. With this much data, you will need to use <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans">MiniBatchKMeans</a> instead of regular KMeans for this. You can increase the batch size to get a smoother curve, 500 should work well. You’ll want to explore larger values of <span class="math notranslate nohighlight">\(k\)</span> than the example in the clustering lecture, though don’t go any higher than 100. You can use the code from the clustering lecture, with appropriate modifications.  Note - this can take a bit of time to cluster the data (it took about 2 minutes on my laptop).</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">=</span> <span class="pre">500</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_clusters</span> <span class="pre">=</span> <span class="pre">k</span></code> where <span class="math notranslate nohighlight">\(2 \leq k\leq 50\)</span>: <code class="docutils literal notranslate"><span class="pre">kmeanses</span> <span class="pre">=</span> <span class="pre">MiniBatchKMeans(n_clusters=k,batch_size=500,random_state=0).</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inertia_</span></code> is defined as the sum of square distances of samples to their nearest neighbor: <code class="docutils literal notranslate"><span class="pre">kmeanses.inertia_</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here</span>
<span class="k">def</span> <span class="nf">plot_inertia</span><span class="p">(</span><span class="n">kmeanses</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;plot the inertia of the provided set of k-means which should correspond to the range of</span>
<span class="sd">    k values provided by start and end. No return value&#39;&#39;&#39;</span>
    <span class="n">ks</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
    <span class="n">inertias</span> <span class="o">=</span> <span class="p">[</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span> <span class="k">for</span> <span class="n">kmeans</span> <span class="ow">in</span> <span class="n">kmeanses</span><span class="p">]</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">inertias</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Clusters (k)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Inertia&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Elbow Method for Optimal k&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Define the range for k</span>
<span class="n">start</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">end</span> <span class="o">=</span> <span class="mi">50</span>
    
<span class="c1"># List to store MiniBatchKMeans models</span>
<span class="n">kmeanses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">MiniBatchKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">post_X_norm</span><span class="p">)</span>
    <span class="n">kmeanses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="p">)</span>

<span class="c1"># Plotting inertia values for the elbow method</span>
<span class="n">plot_inertia</span><span class="p">(</span><span class="n">kmeanses</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/35dcaeb7474c01a7f5e26ea40fd8c01ec097f3c6b324a696af092bf785fdcb10.png" src="../_images/35dcaeb7474c01a7f5e26ea40fd8c01ec097f3c6b324a696af092bf785fdcb10.png" />
</div>
</div>
</section>
<section id="id3">
<h4>1.3<a class="headerlink" href="#id3" title="Link to this heading">#</a></h4>
<p>rubric={accuracy:2,quality:1}</p>
<p>In this exercise you’re going to be comparing different clusterings of the dataset to see if they are consistent, using the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html">adjusted rand index</a> (ARI).  Note that the ARI is not really comparable across different numbers of clusters, so you’ll have to stick to a single <span class="math notranslate nohighlight">\(k\)</span> for the rest of this exercise, based on what you saw in 1.2. The ARI will be negative if the proposed clusters are very different, and closer to 1.0 if they are nearly the same.  Depending on your elbow, among other factors, you could get wildly different mean ARIs, but it should be positive, at least - if it isn’t, you may want to pick a different value of k.  In the next section, you’ll have the opportunity to tune some of the other values.</p>
<p>First, you’re going to be looking at the consistency of clustering across different random iterations of k-means with the same data and parameters. You should run at least 10 different runs of k-means (again using MiniBatchKMeans), exhaustively calculate the pairwise ARI for the resulting label set, and print out an average. It would be a good idea to use a function here, especially since you’ll need to do this again later.</p>
<p>In order to compare two different clusterings, you should feed in the <code class="docutils literal notranslate"><span class="pre">labels_</span></code> arrays from different clusterings to the <code class="docutils literal notranslate"><span class="pre">adjusted_rand_score</span></code> function.</p>
<ul class="simple">
<li><p>using a single <span class="math notranslate nohighlight">\(k\)</span></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">labels_</span></code>: <code class="docutils literal notranslate"><span class="pre">MiniBatchKMeans(n_clusters=k,</span> <span class="pre">batch_size=50,</span> <span class="pre">max_no_improvement=50,random_state=i).fit(X).labels_</span></code></p></li>
<li><p>at least 10 different runs of k-means, exhaustively calculate the <em>pairwise</em> ARI for the resulting label set: <code class="docutils literal notranslate"><span class="pre">adjusted_rand_score(r0,r1),</span> <span class="pre">adjusted_rand_score(r0,r2),</span> <span class="pre">adjusted_rand_score(r0,r3),</span> <span class="pre">...,</span> <span class="pre">adjusted_rand_score(r2,r3),</span> <span class="pre">adjusted_rand_score(r2,r4),</span> <span class="pre">...,</span> <span class="pre">adjusted_rand_score(r7,r8),</span> <span class="pre">...,</span> <span class="pre">adjusted_rand_score(r8,r9)</span></code></p></li>
<li><p>print out an average</p></li>
</ul>
<p><em>The Rand index or Rand measure (named after William M. Rand) in statistics is a measure of the similarity between two data clusterings.</em> (source: <a class="reference external" href="https://en.wikipedia.org/wiki/Rand_index">https://en.wikipedia.org/wiki/Rand_index</a>)</p>
<p>ARI is a symmetric measure: <code class="docutils literal notranslate"><span class="pre">adjusted_rand_score(a,</span> <span class="pre">b)</span> <span class="pre">==</span> <span class="pre">adjusted_rand_score(b,</span> <span class="pre">a)</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">adjusted_rand_score</span>

<span class="n">K</span> <span class="o">=</span> <span class="mi">30</span> <span class="c1"># number of cluster (you can decide the different number)</span>

<span class="c1"># your code here</span>
<span class="k">def</span> <span class="nf">get_ari</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>

    <span class="c1"># 1. Perform clustering n times</span>
    <span class="n">kmeanses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">MiniBatchKMeans</span><span class="p">(</span>
            <span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">max_no_improvement</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">i</span>
        <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">kmeanses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="p">)</span>

    <span class="c1"># 2. Compute pairwise ARIs</span>
    <span class="n">aris</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">ari</span> <span class="o">=</span> <span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">kmeanses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">kmeanses</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
            <span class="n">aris</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ari</span><span class="p">)</span>

    <span class="c1"># 3. Return mean ARI</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">aris</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">aris</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean ARI:&quot;</span><span class="p">,</span> <span class="n">get_ari</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">post_X_norm</span><span class="p">))</span> <span class="c1"># 10 = random state; (1..10)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean ARI: 0.4960327673380925
</pre></div>
</div>
</div>
</div>
</section>
<section id="optional">
<h4>1.4 (Optional)<a class="headerlink" href="#optional" title="Link to this heading">#</a></h4>
<p>rubric={reasoning:1}</p>
<p>There are a few hyperparameters for <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans"><code class="docutils literal notranslate"><span class="pre">MiniBatchKMeans</span></code></a> which will influence clustering performance: e.g. <code class="docutils literal notranslate"><span class="pre">max_no_improvement</span></code>.</p>
<p>Test a few of the parameters of the <span class="math notranslate nohighlight">\(k\)</span>-means (other than <span class="math notranslate nohighlight">\(k\)</span>), trying to improve the consistency calculations from 1.3 (you should get to <code class="docutils literal notranslate"><span class="pre">&gt;</span> <span class="pre">0.4</span></code>) and discuss any major effects in the markdown box below. Keep the best scoring parameters in your final version; you’ll be using them for the result of this exercise.</p>
</section>
<section id="id4">
<h4>1.5 (Optional)<a class="headerlink" href="#id4" title="Link to this heading">#</a></h4>
<p>rubric= {reasoning:1}</p>
<p>Write a function that gives you lists of posts for a given clustering of the data. Using the parameters you choose above, do a run of k-means, select a cluster of medium size (it shouldn’t be the largest or the smallest), print out the list of post ids, and inspect texts from that cluster (at least 5) until you can identify some commonality among posts in the cluster. If you can’t make any sense of the cluster, try another one; it might also help to compare the cluster you pick with another. Write your conclusion in the box below, providing some examples of the language from different posts.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### Your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id5">
<h4>1.6<a class="headerlink" href="#id5" title="Link to this heading">#</a></h4>
<p>rubric= {accuracy:1}</p>
<p>Now use truncated singular value decomposition to lower the dimensionality of the dataset, with k=500. You should use the original data matrix <code class="docutils literal notranslate"><span class="pre">post_X</span></code> here. Store the resulting <code class="docutils literal notranslate"><span class="pre">np.array</span></code> as <code class="docutils literal notranslate"><span class="pre">post_X_500</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">TruncatedSVD</span></code> <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html:">https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html:</a> <code class="docutils literal notranslate"><span class="pre">n_components</span> <span class="pre">=</span> <span class="pre">500</span></code></p>
<!-- Desired dimensionality of output data. Must be strictly less than the number of features. The default value is useful for visualisation. For LSA, a value of 100 is recommended. --><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here</span>

<span class="c1"># Using TruncatedSVD to lower the dimensionality of the dataset</span>
<span class="n">svd</span> <span class="o">=</span> <span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Applying fit_transform on the original data matrix post_X</span>
<span class="n">post_X_500</span> <span class="o">=</span> <span class="n">svd</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">post_X</span><span class="p">)</span>

<span class="c1"># Displaying the shape of the reduced matrix</span>
<span class="n">post_X_500</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(8752, 500)
</pre></div>
</div>
</div>
</div>
</section>
<section id="id6">
<h4>1.7<a class="headerlink" href="#id6" title="Link to this heading">#</a></h4>
<p>rubric= {accuracy:1}</p>
<p>Plot the singular values of <code class="docutils literal notranslate"><span class="pre">post_X_500</span></code>, and pick a sensible new dimensionality, n, n &lt; k, based on what you see (using again the elbow method)</p>
<ul class="simple">
<li><p>plot the singular values (<code class="docutils literal notranslate"><span class="pre">singular_values_</span></code>) where <span class="math notranslate nohighlight">\(k=500\)</span></p></li>
<li><p>pick a sensible new dimensionality <span class="math notranslate nohighlight">\(n\)</span> where  <span class="math notranslate nohighlight">\(n &lt; k\)</span></p></li>
</ul>
<p><strong>The singular value decomposition (SVD) of an <span class="math notranslate nohighlight">\(m \times n\)</span> matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is a factorization of the form  <span class="math notranslate nohighlight">\({\displaystyle \mathbf {U\Sigma V^{*}} }\)</span>,
where the diagonal entries <span class="math notranslate nohighlight">\({\displaystyle \sigma _{i}=\Sigma _{ii}}\)</span> of <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span> are known as the singular values of <span class="math notranslate nohighlight">\(\mathbf {M}\)</span></strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here</span>

<span class="c1"># svd.singular_values_</span>
<span class="k">def</span> <span class="nf">plot_svd</span><span class="p">(</span><span class="n">svd</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">svd</span><span class="o">.</span><span class="n">singular_values_</span><span class="p">)),</span> <span class="n">svd</span><span class="o">.</span><span class="n">singular_values_</span><span class="p">,</span> <span class="s1">&#39;-o&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Component Index&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Singular Value&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Singular Values of Post_X (k=500)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_svd</span><span class="p">(</span><span class="n">svd</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/0c335107bb4ff90843940a0db0ff3cbe33862fcd326834324c39d94ec50a9d60.png" src="../_images/0c335107bb4ff90843940a0db0ff3cbe33862fcd326834324c39d94ec50a9d60.png" />
</div>
</div>
</section>
<section id="id7">
<h4>1.8<a class="headerlink" href="#id7" title="Link to this heading">#</a></h4>
<p>rubric= {accuracy:3,quality:1, efficiency:1}</p>
<p>At this point, you have two matrix representations of the data:</p>
<ol class="arabic simple">
<li><p>Original BOW representation (<code class="docutils literal notranslate"><span class="pre">post_X_norm</span></code>)</p></li>
<li><p>SVD with k=500 (<code class="docutils literal notranslate"><span class="pre">post_X_500</span></code>)</p></li>
</ol>
<p>You will now create two more matrix representations of the data:</p>
<ol class="arabic simple" start="3">
<li><p>SVD with k=n, where <span class="math notranslate nohighlight">\(n\)</span> is based on your elbow analysis from 1.7 (this will have <span class="math notranslate nohighlight">\(n\)</span> columns)</p></li>
<li><p>SVD version using the columns between <span class="math notranslate nohighlight">\(n\)</span> and 500. (this will have 500 - <span class="math notranslate nohighlight">\(n\)</span> columns)</p></li>
</ol>
<p>You can create 3 and 4 just by slicing <code class="docutils literal notranslate"><span class="pre">post_X_500</span></code>; you don’t need to run TruncatedSVD again.</p>
<p>Then, do the same kind of consistency analysis you did in 1.3, but this time using each of matrices 2, 3, and 4. Again, you are creating 10 clusterings for each, and then exhaustively pairing those 10 with each other and checking their consistency using the adjusted rand score.</p>
<p>Your final experiment here will involve testing the clustering label consistency between 1 (the original dataset) and each of the three other matrices. Instead of exhaustively pairing a list of clusterings derived from a single representation (as you did in 1.3 and directly above) to check how consistent the clusterings are, you will be exhaustively pairing two lists of 10 clusterings, one list of clusterings derived using Matrix 1 (i.e. the original representation), and one of clusterings from one of the other three matrices (in 1.3 you were doing comparisons analogous to “pdist”, whereas here you are doing something analogous to “cdist”).</p>
<p>This should result in 3 average consistency values, one for each of matrices 2, 3, and 4, which you should take as a measure of how well each representation is able to preserve the information in the original for the purposes of clustering. With the results for 2, 3, and 4 for the internal consistency testing, you should be displaying a total of 6 numbers here, make sure you clearly identify which is which! For full points, use functions, and try to avoid redoing the same clustering again and again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here</span>

<span class="k">def</span> <span class="nf">get_pairwise_ari</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">):</span>
    
    <span class="c1"># 1. Initialize Lists for Clustering Results</span>
    <span class="n">kmeanses1</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">kmeanses2</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># 2. Run MiniBatchKMeans on X1 and X2</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">kmeans1</span> <span class="o">=</span> <span class="n">MiniBatchKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">max_no_improvement</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="p">)</span>
        <span class="n">kmeans2</span> <span class="o">=</span> <span class="n">MiniBatchKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">max_no_improvement</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X2</span><span class="p">)</span>
        <span class="n">kmeanses1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans1</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
        <span class="n">kmeanses2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans2</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>

    <span class="c1"># 3. Compute Pairwise ARIs</span>
    <span class="n">aris</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">aris</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">kmeanses1</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">kmeanses2</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>

    <span class="c1"># 4. Return the average ARI</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">aris</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">aris</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Prepare `post_X_500` using TruncatedSVD</span>
<span class="n">svd</span> <span class="o">=</span> <span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">post_X_500</span> <span class="o">=</span> <span class="n">svd</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">post_X_norm</span><span class="p">)</span>

<span class="c1"># Determine `n` based on elbow method</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># Prepare `post_X_0_to_50` and `post_X_50_to_500`</span>
<span class="n">post_X_0_to_50</span> <span class="o">=</span> <span class="n">post_X_500</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n</span><span class="p">]</span>
<span class="n">post_X_50_to_500</span> <span class="o">=</span> <span class="n">post_X_500</span><span class="p">[:,</span> <span class="n">n</span><span class="p">:</span><span class="mi">500</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Internal consistency:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean ARI 0-500:&quot;</span><span class="p">,</span> <span class="n">get_ari</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">post_X_500</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean ARI 0-50:&quot;</span><span class="p">,</span> <span class="n">get_ari</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">post_X_0_to_50</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean ARI 50-500:&quot;</span><span class="p">,</span> <span class="n">get_ari</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">post_X_50_to_500</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Consistency with original matrix X_norm:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean pairwise ARI 0-500:&quot;</span><span class="p">,</span> <span class="n">get_pairwise_ari</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">post_X_500</span><span class="p">,</span> <span class="n">post_X_norm</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean pairwise ARI 0-50:&quot;</span><span class="p">,</span> <span class="n">get_pairwise_ari</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">post_X_0_to_50</span><span class="p">,</span> <span class="n">post_X_norm</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean pairwise ARI 50-500:&quot;</span><span class="p">,</span> <span class="n">get_pairwise_ari</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">post_X_50_to_500</span><span class="p">,</span> <span class="n">post_X_norm</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Internal consistency:
Mean ARI 0-500: 0.3596024353099056
Mean ARI 0-50: 0.3889865101892922
Mean ARI 50-500: 0.05494705192554139

Consistency with original matrix X_norm:
Mean pairwise ARI 0-500: 0.3937042505895092
Mean pairwise ARI 0-50: 0.03612607689321647
Mean pairwise ARI 50-500: 0.0002734238307480625
</pre></div>
</div>
</div>
</div>
</section>
<section id="id8">
<h4>1.9<a class="headerlink" href="#id8" title="Link to this heading">#</a></h4>
<p>rubric= {reasoning:2}</p>
<p>Interpret the relative performance of the three vector representations based on what you understand about SVD. In particular, you should discuss whether your choice of k from 1.7 (using the elbow method) seems to be a good one, in terms of preserving the information contained in the original document representation.</p>
<p><strong>Answer:</strong></p>
<p>From the results, we can see that the first 50 principal components (0-50) of SVD can capture the core features of the data well, have high internal consistency (0.39), and achieve a good balance between dimensionality reduction efficiency and information retention. The subsequent principal components (50-500) mainly contain low-variance features or noise, and their consistency and information retention effects are extremely low (0.05 and close to 0). Overall, it is reasonable to choose a dimension of <code class="docutils literal notranslate"><span class="pre">k=30</span></code> based on the elbow rule, which not only effectively reduces the dimension but also retains enough information for clustering, but may lose some consistency with the details of the original matrix.</p>
</section>
</section>
<section id="part-2-topic-modelling">
<h3>Part 2: Topic modelling<a class="headerlink" href="#part-2-topic-modelling" title="Link to this heading">#</a></h3>
<section id="id9">
<h4>2.1<a class="headerlink" href="#id9" title="Link to this heading">#</a></h4>
<p>rubric={accuracy:1}</p>
<p>Using the blog data, build an LDA model with 100 topics. Use online learning, and set the verbosity option to 2 and evaluate_every to 1, so the you can see the process of training and the perplexity after each iteration. Increase the total number of iterations and run again if perplexity has not converged (you can say it has coveraged if there is less than a 5 point drop in perplexity in the final iteration). This will take a while (probably at least half an hour), so work on something else while you wait….  It may also make sense after you get it working to dump the results to a file, so you don’t have to run this every time you start up the kernel…</p>
<p>Blei, D. M., Ng, A. Y., &amp; Jordan, M. I. (2003). Latent Dirichlet Allocation. <em>Journal of Machine Learning Research</em>, 3(4–5), 993–1022.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">post_X</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LatentDirichletAllocation</span></code>: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html">https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html</a></p></li>
<li><p>100 topics <code class="docutils literal notranslate"><span class="pre">n_components</span></code>,</p></li>
<li><p>use <code class="docutils literal notranslate"><span class="pre">&quot;online&quot;</span></code> as a <code class="docutils literal notranslate"><span class="pre">learning_method</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">verbosity</span></code> option = <strong>0</strong>, otherwise, it prints A LOT.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">evaluate_every</span></code> = 1</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here, takes time to run... (&gt;13min)</span>

<span class="c1"># Building the LDA model with 100 topics</span>
<span class="n">lda</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span>
    <span class="n">n_components</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>          <span class="c1"># Number of topics</span>
    <span class="n">learning_method</span><span class="o">=</span><span class="s2">&quot;online&quot;</span><span class="p">,</span>  <span class="c1"># Use online learning</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>               <span class="c1"># Start with 50 iterations</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>            <span class="c1"># Reproducibility</span>
    <span class="n">evaluate_every</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>          <span class="c1"># Evaluate perplexity after each iteration</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="c1"># Fit the LDA model to the original post_X data</span>
<span class="n">lda</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">post_X</span><span class="p">)</span>

<span class="c1"># Output perplexity after the final iteration</span>
<span class="n">final_perplexity</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">perplexity</span><span class="p">(</span><span class="n">post_X</span><span class="p">)</span>
<span class="n">final_perplexity</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(4668.053048781353)
</pre></div>
</div>
</div>
</div>
</section>
<section id="id10">
<h4>2.2<a class="headerlink" href="#id10" title="Link to this heading">#</a></h4>
<p>rubric={accuracy:3}</p>
<p>For each topic in the model, print out the topic number (0 to 99), the sum of the corresponding row of components_ (the total psuedo counts for that topic), and the 15 words which have the highest number of psuedocounts (in components_) for that topic, high count word first. <strong>Hint:</strong> the CountVectorizer that you built in Part 0 will be needed here, because you can use it to translate feature index numbers into words.</p>
<p>You should exclude topic words which have a psuedocount of less than 5. It’s possible that some topics end up with an empty list of words after filtering filter step, but that’s okay.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Your code here</span>

<span class="k">def</span> <span class="nf">print_topics</span><span class="p">(</span><span class="n">lda_model</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Print topics from an LDA model with top words and their pseudocounts.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - lda_model: Trained LDA model (LatentDirichletAllocation).</span>
<span class="sd">    - vectorizer: Fitted CountVectorizer to map indices to words.</span>
<span class="sd">    - top_n: Number of top words to display for each topic (default=15).</span>
<span class="sd">    - min_count: Minimum pseudocount to include a word in the topic (default=5).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">feature_names</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">topic_idx</span><span class="p">,</span> <span class="n">topic</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lda_model</span><span class="o">.</span><span class="n">components_</span><span class="p">):</span>
        <span class="c1"># Calculate the total pseudocounts for the topic</span>
        <span class="n">topic_sum</span> <span class="o">=</span> <span class="n">topic</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="c1"># Filter and sort words based on pseudocounts</span>
        <span class="n">filtered_words</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">topic</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">topic</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Sort by descending pseudocounts</span>
            <span class="k">if</span> <span class="n">topic</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">min_count</span>
        <span class="p">]</span>

        <span class="c1"># Extract the top N words</span>
        <span class="n">top_words</span> <span class="o">=</span> <span class="n">filtered_words</span><span class="p">[:</span><span class="n">top_n</span><span class="p">]</span>

        <span class="c1"># Display topic information</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Topic number: </span><span class="si">{</span><span class="n">topic_idx</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">topic_sum</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">top_words</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">([</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">top_words</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[]&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_topics</span><span class="p">(</span><span class="n">lda</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Topic number: 0, 3244.333642148209
[&#39;da&#39;, &#39;de&#39;, &#39;angel&#39;, &#39;y&#39;, &#39;que&#39;, &#39;el&#39;, &#39;kate&#39;, &#39;max&#39;, &#39;se&#39;, &#39;un&#39;, &#39;sharon&#39;, &#39;te&#39;, &#39;bald&#39;, &#39;ü&#39;, &#39;har&#39;]

Topic number: 1, 320555.25304718333
[&#39;car&#39;, &#39;morning&#39;, &#39;week&#39;, &#39;decided&#39;, &#39;hours&#39;, &#39;finally&#39;, &#39;hour&#39;, &#39;minutes&#39;, &#39;asked&#39;, &#39;wasn&#39;, &#39;weekend&#39;, &#39;bit&#39;, &#39;saw&#39;, &#39;10&#39;, &#39;30&#39;]

Topic number: 2, 17762.535713104662
[&#39;music&#39;, &#39;song&#39;, &#39;band&#39;, &#39;songs&#39;, &#39;cd&#39;, &#39;rock&#39;, &#39;guitar&#39;, &#39;concert&#39;, &#39;play&#39;, &#39;sing&#39;, &#39;album&#39;, &#39;singing&#39;, &#39;listening&#39;, &#39;listen&#39;, &#39;played&#39;]

Topic number: 3, 6511.197909348428
[&#39;beach&#39;, &#39;ride&#39;, &#39;trip&#39;, &#39;hotel&#39;, &#39;road&#39;, &#39;river&#39;, &#39;park&#39;, &#39;island&#39;, &#39;tour&#39;, &#39;fireworks&#39;, &#39;miles&#39;, &#39;swimming&#39;, &#39;headed&#39;, &#39;sea&#39;, &#39;beautiful&#39;]

Topic number: 4, 149.39000000017614
[]

Topic number: 5, 3636.3156605642985
[&#39;room&#39;, &#39;living&#39;, &#39;walls&#39;, &#39;bedroom&#39;, &#39;paint&#39;, &#39;wood&#39;, &#39;closet&#39;, &#39;painted&#39;, &#39;yard&#39;, &#39;fridge&#39;, &#39;furniture&#39;, &#39;carpet&#39;, &#39;storage&#39;, &#39;curtains&#39;, &#39;project&#39;]

Topic number: 6, 1843.7387188342286
[&#39;player&#39;, &#39;canada&#39;, &#39;canadian&#39;, &#39;russian&#39;, &#39;canadians&#39;, &#39;russia&#39;, &#39;stack&#39;, &#39;chess&#39;, &#39;eddie&#39;, &#39;referee&#39;, &#39;val&#39;, &#39;dope&#39;, &#39;shouts&#39;, &#39;flush&#39;, &#39;conveniently&#39;]

Topic number: 7, 149.39000000017555
[]

Topic number: 8, 149.39000000017205
[]

Topic number: 9, 16175.571435644915
[&#39;haha&#39;, &#39;lol&#39;, &#39;hehe&#39;, &#39;hahaha&#39;, &#39;nite&#39;, &#39;ppl&#39;, &#39;wit&#39;, &#39;soo&#39;, &#39;ok&#39;, &#39;cuz&#39;, &#39;hmm&#39;, &#39;wen&#39;, &#39;cute&#39;, &#39;bout&#39;, &#39;ive&#39;]

Topic number: 10, 106740.90017790193
[&#39;god&#39;, &#39;heart&#39;, &#39;church&#39;, &#39;jesus&#39;, &#39;believe&#39;, &#39;fear&#39;, &#39;lord&#39;, &#39;words&#39;, &#39;others&#39;, &#39;human&#39;, &#39;faith&#39;, &#39;must&#39;, &#39;pain&#39;, &#39;child&#39;, &#39;lives&#39;]

Topic number: 11, 2780.125324874297
[&#39;sex&#39;, &#39;girls&#39;, &#39;sexual&#39;, &#39;sexy&#39;, &#39;brittany&#39;, &#39;christine&#39;, &#39;toys&#39;, &#39;chem&#39;, &#39;horny&#39;, &#39;attracted&#39;, &#39;predator&#39;, &#39;freinds&#39;, &#39;engaging&#39;, &#39;sn&#39;, &#39;erica&#39;]

Topic number: 12, 149.39000000017677
[]

Topic number: 13, 13816.24454382213
[&#39;e&#39;, &#39;b&#39;, &#39;c&#39;, &#39;o&#39;, &#39;pm&#39;, &#39;p&#39;, &#39;w&#39;, &#39;r&#39;, &#39;l&#39;, &#39;h&#39;, &#39;f&#39;, &#39;v&#39;, &#39;n&#39;, &#39;k&#39;, &#39;g&#39;]

Topic number: 14, 24424.09791611095
[&#39;movie&#39;, &#39;book&#39;, &#39;read&#39;, &#39;story&#39;, &#39;books&#39;, &#39;film&#39;, &#39;reading&#39;, &#39;character&#39;, &#39;harry&#39;, &#39;characters&#39;, &#39;king&#39;, &#39;series&#39;, &#39;writing&#39;, &#39;interesting&#39;, &#39;stories&#39;]

Topic number: 15, 1126.5884516073227
[&#39;shake&#39;, &#39;pig&#39;, &#39;sons&#39;, &#39;cage&#39;, &#39;victims&#39;, &#39;farmer&#39;, &#39;aunty&#39;, &#39;myth&#39;, &#39;prisoners&#39;, &#39;thanking&#39;, &#39;oprah&#39;, &#39;mice&#39;, &#39;expectation&#39;, &#39;tainted&#39;, &#39;explicit&#39;]

Topic number: 16, 51063.35646672304
[&#39;children&#39;, &#39;state&#39;, &#39;law&#39;, &#39;states&#39;, &#39;government&#39;, &#39;religion&#39;, &#39;society&#39;, &#39;against&#39;, &#39;marriage&#39;, &#39;united&#39;, &#39;human&#39;, &#39;rights&#39;, &#39;power&#39;, &#39;christian&#39;, &#39;culture&#39;]

Topic number: 17, 23008.648990169306
[&#39;computer&#39;, &#39;internet&#39;, &#39;use&#39;, &#39;0&#39;, &#39;email&#39;, &#39;mail&#39;, &#39;software&#39;, &#39;web&#39;, &#39;windows&#39;, &#39;system&#39;, &#39;microsoft&#39;, &#39;file&#39;, &#39;using&#39;, &#39;e&#39;, &#39;data&#39;]

Topic number: 18, 77907.0162989226
[&#39;lol&#39;, &#39;yeah&#39;, &#39;guys&#39;, &#39;cool&#39;, &#39;bored&#39;, &#39;gonna&#39;, &#39;funny&#39;, &#39;girl&#39;, &#39;awesome&#39;, &#39;anyways&#39;, &#39;mom&#39;, &#39;kinda&#39;, &#39;talked&#39;, &#39;movie&#39;, &#39;ok&#39;]

Topic number: 19, 1468.4451717921252
[&#39;pay&#39;, &#39;depend&#39;, &#39;loan&#39;, &#39;absent&#39;, &#39;weirdo&#39;, &#39;proposals&#39;, &#39;sow&#39;, &#39;equate&#39;, &#39;negotiating&#39;]

Topic number: 20, 447.96091806614083
[&#39;sam&#39;, &#39;coordinator&#39;]

Topic number: 21, 86133.94493372922
[&#39;eyes&#39;, &#39;head&#39;, &#39;face&#39;, &#39;water&#39;, &#39;cold&#39;, &#39;inside&#39;, &#39;dream&#39;, &#39;light&#39;, &#39;side&#39;, &#39;hear&#39;, &#39;door&#39;, &#39;rain&#39;, &#39;open&#39;, &#39;run&#39;, &#39;walk&#39;]

Topic number: 22, 149.39000000018586
[]

Topic number: 23, 7784.603713185883
[&#39;chicken&#39;, &#39;milk&#39;, &#39;eat&#39;, &#39;cheese&#39;, &#39;bread&#39;, &#39;cream&#39;, &#39;sugar&#39;, &#39;pizza&#39;, &#39;cup&#39;, &#39;cook&#39;, &#39;oil&#39;, &#39;juice&#39;, &#39;meat&#39;, &#39;add&#39;, &#39;butter&#39;]

Topic number: 24, 149.3900000001909
[]

Topic number: 25, 178.5701769382119
[&#39;dishwasher&#39;, &#39;glenn&#39;]

Topic number: 26, 149.39000000018382
[]

Topic number: 27, 149.39000000018342
[]

Topic number: 28, 302.6439638885669
[&#39;lance&#39;, &#39;melanie&#39;, &#39;missy&#39;, &#39;armstrong&#39;, &#39;alli&#39;]

Topic number: 29, 3018.413704324361
[&#39;hate&#39;, &#39;burn&#39;, &#39;ain&#39;, &#39;burning&#39;, &#39;ooh&#39;, &#39;oooh&#39;, &#39;ooo&#39;, &#39;party&#39;, &#39;used&#39;, &#39;side&#39;, &#39;courtney&#39;, &#39;body&#39;, &#39;bruise&#39;, &#39;might&#39;, &#39;feeling&#39;]

Topic number: 30, 25673.700169180513
[&#39;8&#39;, &#39;10&#39;, &#39;6&#39;, &#39;7&#39;, &#39;11&#39;, &#39;9&#39;, &#39;12&#39;, &#39;143&#39;, &#39;16&#39;, &#39;14&#39;, &#39;15&#39;, &#39;22&#39;, &#39;13&#39;, &#39;20&#39;, &#39;19&#39;]

Topic number: 31, 5456.378612563189
[&#39;camp&#39;, &#39;brian&#39;, &#39;dr&#39;, &#39;pregnant&#39;, &#39;meeting&#39;, &#39;dear&#39;, &#39;pregnancy&#39;, &#39;male&#39;, &#39;death&#39;, &#39;anthony&#39;, &#39;cus&#39;, &#39;assistant&#39;, &#39;production&#39;, &#39;babies&#39;, &#39;yu&#39;]

Topic number: 32, 7218.54610625151
[&#39;na&#39;, &#39;sa&#39;, &#39;ko&#39;, &#39;ang&#39;, &#39;ng&#39;, &#39;ako&#39;, &#39;pa&#39;, &#39;mo&#39;, &#39;lang&#39;, &#39;si&#39;, &#39;hindi&#39;, &#39;ka&#39;, &#39;mga&#39;, &#39;pero&#39;, &#39;naman&#39;]

Topic number: 33, 20128.899154253057
[&#39;yes&#39;, &#39;name&#39;, &#39;hair&#39;, &#39;favorite&#39;, &#39;color&#39;, &#39;number&#39;, &#39;nope&#39;, &#39;blue&#39;, &#39;brown&#39;, &#39;chocolate&#39;, &#39;drink&#39;, &#39;current&#39;, &#39;yeah&#39;, &#39;smoke&#39;, &#39;black&#39;]

Topic number: 34, 1677.2659465823517
[&#39;south&#39;, &#39;corn&#39;, &#39;michigan&#39;, &#39;virginia&#39;, &#39;fifteen&#39;, &#39;carolina&#39;, &#39;kansas&#39;, &#39;illinois&#39;, &#39;iowa&#39;, &#39;minnesota&#39;, &#39;indiana&#39;, &#39;georgia&#39;, &#39;ski&#39;, &#39;billion&#39;, &#39;dakota&#39;]

Topic number: 35, 149.39000000016284
[]

Topic number: 36, 7394.686687745279
[&#39;2004&#39;, &#39;james&#39;, &#39;june&#39;, &#39;2003&#39;, &#39;august&#39;, &#39;members&#39;, &#39;jake&#39;, &#39;sound&#39;, &#39;base&#39;, &#39;jim&#39;, &#39;ship&#39;, &#39;moon&#39;, &#39;2002&#39;, &#39;black&#39;, &#39;event&#39;]

Topic number: 37, 11973.770753063636
[&#39;urllink&#39;, &#39;website&#39;, &#39;version&#39;, &#39;download&#39;, &#39;battery&#39;, &#39;os&#39;, &#39;mac&#39;, &#39;laptop&#39;, &#39;apple&#39;, &#39;machine&#39;, &#39;vs&#39;, &#39;brought&#39;, &#39;install&#39;, &#39;mp3&#39;, &#39;fan&#39;]

Topic number: 38, 2061.594341766781
[&#39;coffee&#39;, &#39;sox&#39;, &#39;boston&#39;, &#39;starbucks&#39;, &#39;nomar&#39;, &#39;goddamn&#39;, &#39;signal&#39;, &#39;yankees&#39;, &#39;borrowed&#39;, &#39;goth&#39;, &#39;gw&#39;, &#39;mug&#39;, &#39;damon&#39;, &#39;dodgeball&#39;, &#39;vacations&#39;]

Topic number: 39, 3833.1590595569487
[&#39;says&#39;, &#39;blah&#39;, &#39;daddy&#39;, &#39;tha&#39;, &#39;jo&#39;, &#39;rick&#39;, &#39;ken&#39;, &#39;stead&#39;, &#39;meds&#39;, &#39;clark&#39;, &#39;shit&#39;, &#39;pagan&#39;, &#39;cunt&#39;, &#39;hiv&#39;, &#39;walks&#39;]

Topic number: 40, 777.5281496022642
[&#39;paul&#39;, &#39;hong&#39;, &#39;kong&#39;, &#39;lorz&#39;, &#39;aussie&#39;, &#39;censored&#39;, &#39;underway&#39;, &#39;fancied&#39;, &#39;storming&#39;]

Topic number: 41, 149.39000000016563
[]

Topic number: 42, 15322.721011276042
[&#39;game&#39;, &#39;play&#39;, &#39;team&#39;, &#39;games&#39;, &#39;played&#39;, &#39;playing&#39;, &#39;ball&#39;, &#39;win&#39;, &#39;players&#39;, &#39;won&#39;, &#39;match&#39;, &#39;football&#39;, &#39;season&#39;, &#39;soccer&#39;, &#39;second&#39;]

Topic number: 43, 479.89073951465207
[&#39;prince&#39;, &#39;newsletter&#39;, &#39;kayaking&#39;, &#39;skilled&#39;, &#39;edinburgh&#39;, &#39;homo&#39;, &#39;empathy&#39;, &#39;su&#39;, &#39;uneven&#39;, &#39;survivors&#39;, &#39;fireplace&#39;, &#39;edged&#39;, &#39;lash&#39;]

Topic number: 44, 391540.08987149934
[&#39;doesn&#39;, &#39;thinking&#39;, &#39;sometimes&#39;, &#39;makes&#39;, &#39;anyone&#39;, &#39;probably&#39;, &#39;happy&#39;, &#39;kind&#39;, &#39;care&#39;, &#39;might&#39;, &#39;girl&#39;, &#39;point&#39;, &#39;live&#39;, &#39;seems&#39;, &#39;fact&#39;]

Topic number: 45, 4935.668873881275
[&#39;show&#39;, &#39;tv&#39;, &#39;shows&#39;, &#39;watching&#39;, &#39;sara&#39;, &#39;television&#39;, &#39;series&#39;, &#39;actors&#39;, &#39;emily&#39;, &#39;screen&#39;, &#39;karen&#39;, &#39;tara&#39;, &#39;cast&#39;, &#39;episodes&#39;, &#39;doom&#39;]

Topic number: 46, 149.39000000016247
[]

Topic number: 47, 284.1108938431322
[&#39;priest&#39;, &#39;sobbing&#39;, &#39;priests&#39;, &#39;invaded&#39;, &#39;initiation&#39;]

Topic number: 48, 149.3900000001818
[]

Topic number: 49, 171.71315970618116
[&#39;explanations&#39;]

Topic number: 50, 42470.219342535886
[&#39;war&#39;, &#39;bush&#39;, &#39;president&#39;, &#39;country&#39;, &#39;american&#39;, &#39;kerry&#39;, &#39;america&#39;, &#39;news&#39;, &#39;iraq&#39;, &#39;political&#39;, &#39;john&#39;, &#39;vote&#39;, &#39;george&#39;, &#39;moore&#39;, &#39;military&#39;]

Topic number: 51, 11952.24446582784
[&#39;dad&#39;, &#39;mom&#39;, &#39;family&#39;, &#39;kids&#39;, &#39;mother&#39;, &#39;father&#39;, &#39;cousin&#39;, &#39;uncle&#39;, &#39;daughter&#39;, &#39;aunt&#39;, &#39;grandma&#39;, &#39;cousins&#39;, &#39;boat&#39;, &#39;lake&#39;, &#39;tht&#39;]

Topic number: 52, 48587.81672987819
[&#39;n&#39;, &#39;den&#39;, &#39;dun&#39;, &#39;tt&#39;, &#39;coz&#39;, &#39;mi&#39;, &#39;cos&#39;, &#39;la&#39;, &#39;wif&#39;, &#39;wat&#39;, &#39;abt&#39;, &#39;juz&#39;, &#39;tat&#39;, &#39;u&#39;, &#39;noe&#39;]

Topic number: 53, 149.39000000017097
[]

Topic number: 54, 20113.72807450721
[&#39;u&#39;, &#39;ur&#39;, &#39;cause&#39;, &#39;wanna&#39;, &#39;ya&#39;, &#39;gonna&#39;, &#39;miss&#39;, &#39;n&#39;, &#39;cuz&#39;, &#39;gotta&#39;, &#39;ppl&#39;, &#39;r&#39;, &#39;goin&#39;, &#39;y&#39;, &#39;chorus&#39;]

Topic number: 55, 11078.755004728431
[&#39;la&#39;, &#39;bar&#39;, &#39;beer&#39;, &#39;dance&#39;, &#39;dancing&#39;, &#39;drink&#39;, &#39;drinking&#39;, &#39;club&#39;, &#39;party&#39;, &#39;charlie&#39;, &#39;drunk&#39;, &#39;san&#39;, &#39;men&#39;, &#39;ben&#39;, &#39;teh&#39;]

Topic number: 56, 483.3788709217529
[&#39;existed&#39;, &#39;mummy&#39;, &#39;samantha&#39;, &#39;newton&#39;, &#39;clique&#39;, &#39;alyssa&#39;, &#39;societies&#39;, &#39;savage&#39;]

Topic number: 57, 149.3900000001712
[]

Topic number: 58, 2844.4207637713603
[&#39;yang&#39;, &#39;aku&#39;, &#39;ni&#39;, &#39;fire&#39;, &#39;mama&#39;, &#39;wo&#39;, &#39;die&#39;, &#39;abuse&#39;, &#39;di&#39;, &#39;medicine&#39;, &#39;nak&#39;, &#39;chi&#39;, &#39;tak&#39;, &#39;jill&#39;, &#39;prophet&#39;]

Topic number: 59, 379.960623778909
[&#39;tiger&#39;, &#39;woot&#39;, &#39;cali&#39;, &#39;tri&#39;, &#39;carey&#39;, &#39;dynamite&#39;, &#39;connie&#39;, &#39;desparate&#39;]

Topic number: 60, 56301.551809079625
[&#39;class&#39;, &#39;fucking&#39;, &#39;teacher&#39;, &#39;shit&#39;, &#39;fuck&#39;, &#39;ok&#39;, &#39;hell&#39;, &#39;damn&#39;, &#39;bitch&#39;, &#39;mr&#39;, &#39;stupid&#39;, &#39;ass&#39;, &#39;group&#39;, &#39;classes&#39;, &#39;test&#39;]

Topic number: 61, 149.39000000016944
[]

Topic number: 62, 149.39000000018194
[]

Topic number: 63, 1634.5986445812887
[&#39;green&#39;, &#39;garden&#39;, &#39;italian&#39;, &#39;plant&#39;, &#39;plants&#39;, &#39;tomato&#39;, &#39;tomatoes&#39;, &#39;basil&#39;, &#39;nursery&#39;, &#39;peppers&#39;, &#39;herbs&#39;, &#39;harvest&#39;, &#39;ninth&#39;, &#39;mop&#39;, &#39;gardening&#39;]

Topic number: 64, 149.39000000017563
[]

Topic number: 65, 149.39000000017285
[]

Topic number: 66, 3328.1694468055207
[&#39;city&#39;, &#39;english&#39;, &#39;chinese&#39;, &#39;country&#39;, &#39;japanese&#39;, &#39;british&#39;, &#39;japan&#39;, &#39;asian&#39;, &#39;korean&#39;, &#39;toronto&#39;, &#39;queen&#39;, &#39;stores&#39;, &#39;korea&#39;, &#39;bookstore&#39;, &#39;store&#39;]

Topic number: 67, 473.0629421754564
[&#39;washing&#39;, &#39;xd&#39;, &#39;calculus&#39;, &#39;docs&#39;, &#39;loo&#39;, &#39;manic&#39;, &#39;o_o&#39;, &#39;alarmed&#39;, &#39;jerome&#39;]

Topic number: 68, 278.0577384527791
[&#39;ga&#39;, &#39;liner&#39;, &#39;keke&#39;, &#39;outskirts&#39;, &#39;doh&#39;]

Topic number: 69, 30532.558325747472
[&#39;bag&#39;, &#39;looked&#39;, &#39;black&#39;, &#39;white&#39;, &#39;red&#39;, &#39;car&#39;, &#39;wearing&#39;, &#39;hair&#39;, &#39;shirt&#39;, &#39;hand&#39;, &#39;shoes&#39;, &#39;boy&#39;, &#39;hands&#39;, &#39;door&#39;, &#39;walked&#39;]

Topic number: 70, 101217.84618554576
[&#39;information&#39;, &#39;however&#39;, &#39;working&#39;, &#39;use&#39;, &#39;able&#39;, &#39;order&#39;, &#39;project&#39;, &#39;etc&#39;, &#39;experience&#39;, &#39;college&#39;, &#39;research&#39;, &#39;future&#39;, &#39;number&#39;, &#39;each&#39;, &#39;level&#39;]

Topic number: 71, 149.39000000018586
[]

Topic number: 72, 236.8859208476377
[&#39;kris&#39;, &#39;slit&#39;, &#39;apologizing&#39;]

Topic number: 73, 16885.19418859067
[&#39;im&#39;, &#39;dont&#39;, &#39;didnt&#39;, &#39;thats&#39;, &#39;cant&#39;, &#39;yea&#39;, &#39;doesnt&#39;, &#39;ill&#39;, &#39;shes&#39;, &#39;wasnt&#39;, &#39;hes&#39;, &#39;alot&#39;, &#39;havent&#39;, &#39;theres&#39;, &#39;whats&#39;]

Topic number: 74, 149.39000000016284
[]

Topic number: 75, 17711.82344076571
[&#39;women&#39;, &#39;dog&#39;, &#39;baby&#39;, &#39;weight&#39;, &#39;food&#39;, &#39;eat&#39;, &#39;body&#39;, &#39;water&#39;, &#39;men&#39;, &#39;fat&#39;, &#39;woman&#39;, &#39;dogs&#39;, &#39;eating&#39;, &#39;fish&#39;, &#39;doctor&#39;]

Topic number: 76, 6411.3643158366385
[&#39;police&#39;, &#39;christmas&#39;, &#39;london&#39;, &#39;round&#39;, &#39;run&#39;, &#39;track&#39;, &#39;cable&#39;, &#39;hat&#39;, &#39;station&#39;, &#39;socks&#39;, &#39;bike&#39;, &#39;black&#39;, &#39;crime&#39;, &#39;pattern&#39;, &#39;officers&#39;]

Topic number: 77, 3860.035652368774
[&#39;mary&#39;, &#39;gold&#39;, &#39;bf&#39;, &#39;olympics&#39;, &#39;shell&#39;, &#39;greek&#39;, &#39;grace&#39;, &#39;spider&#39;, &#39;subjects&#39;, &#39;valley&#39;, &#39;greece&#39;, &#39;halo&#39;, &#39;olympic&#39;, &#39;angela&#39;, &#39;jacob&#39;]

Topic number: 78, 171.84398134146315
[&#39;brandy&#39;]

Topic number: 79, 327.83838992665864
[&#39;corps&#39;, &#39;eugene&#39;, &#39;shaving&#39;, &#39;lotion&#39;, &#39;charley&#39;, &#39;inflatable&#39;, &#39;oily&#39;]

Topic number: 80, 149.39000000016262
[]

Topic number: 81, 226.04332339269493
[&#39;eden&#39;, &#39;dancers&#39;, &#39;workshops&#39;]

Topic number: 82, 5606.900221673937
[&#39;art&#39;, &#39;camera&#39;, &#39;photo&#39;, &#39;pictures&#39;, &#39;video&#39;, &#39;photos&#39;, &#39;image&#39;, &#39;digital&#39;, &#39;images&#39;, &#39;creative&#39;, &#39;raw&#39;, &#39;print&#39;, &#39;studio&#39;, &#39;frame&#39;, &#39;pics&#39;]

Topic number: 83, 4238.557510596486
[&#39;x&#39;, &#39;_&#39;, &#39;fred&#39;, &#39;slow&#39;, &#39;cows&#39;, &#39;er&#39;, &#39;stones&#39;, &#39;lion&#39;, &#39;melody&#39;, &#39;scent&#39;, &#39;warmth&#39;, &#39;triple&#39;, &#39;waves&#39;, &#39;theatre&#39;, &#39;invest&#39;]

Topic number: 84, 26874.115446548403
[&#39;money&#39;, &#39;job&#39;, &#39;company&#39;, &#39;business&#39;, &#39;service&#39;, &#39;customer&#39;, &#39;market&#39;, &#39;price&#39;, &#39;phone&#39;, &#39;000&#39;, &#39;cost&#39;, &#39;card&#39;, &#39;paid&#39;, &#39;companies&#39;, &#39;sell&#39;]

Topic number: 85, 149.39000000016955
[]

Topic number: 86, 250.9868197093545
[&#39;eu&#39;, &#39;washroom&#39;, &#39;whitney&#39;, &#39;epiphany&#39;]

Topic number: 87, 149.39000000017205
[]

Topic number: 88, 387.3686718449052
[&#39;tank&#39;, &#39;tanks&#39;, &#39;overcoming&#39;, &#39;imperfect&#39;, &#39;lofty&#39;, &#39;refering&#39;]

Topic number: 89, 1169.9189315592025
[&#39;virus&#39;, &#39;robot&#39;, &#39;celebrity&#39;, &#39;noah&#39;, &#39;taylor&#39;, &#39;fever&#39;, &#39;thesis&#39;, &#39;theyre&#39;, &#39;chuck&#39;, &#39;infected&#39;, &#39;motel&#39;, &#39;province&#39;, &#39;pj&#39;, &#39;nile&#39;, &#39;mosquitoes&#39;]

Topic number: 90, 149.39000000018223
[]

Topic number: 91, 4136.808723585296
[&#39;tree&#39;, &#39;bridge&#39;, &#39;animals&#39;, &#39;trees&#39;, &#39;zoo&#39;, &#39;forest&#39;, &#39;los&#39;, &#39;susan&#39;, &#39;tower&#39;, &#39;dallas&#39;, &#39;humans&#39;, &#39;wild&#39;, &#39;angeles&#39;, &#39;diana&#39;, &#39;visitors&#39;]

Topic number: 92, 282.8960272138839
[&#39;rome&#39;, &#39;elbow&#39;, &#39;sculpture&#39;, &#39;freedoms&#39;]

Topic number: 93, 1630.140103946474
[&#39;singapore&#39;, &#39;ho&#39;, &#39;sub&#39;, &#39;jump&#39;, &#39;steak&#39;, &#39;malaysia&#39;, &#39;audition&#39;, &#39;lai&#39;, &#39;customs&#39;, &#39;kl&#39;, &#39;au&#39;, &#39;pas&#39;, &#39;hari&#39;, &#39;sap&#39;, &#39;malaysian&#39;]

Topic number: 94, 149.39000000018706
[]

Topic number: 95, 3237.7362429434625
[&#39;al&#39;, &#39;attack&#39;, &#39;ryan&#39;, &#39;security&#39;, &#39;clinton&#39;, &#39;attacks&#39;, &#39;bin&#39;, &#39;ad&#39;, &#39;terrorist&#39;, &#39;attacked&#39;, &#39;terrorists&#39;, &#39;ads&#39;, &#39;et&#39;, &#39;laden&#39;, &#39;terrorism&#39;]

Topic number: 96, 176.1881871937792
[&#39;wrists&#39;]

Topic number: 97, 12334.034452927634
[&#39;blog&#39;, &#39;com&#39;, &#39;site&#39;, &#39;www&#39;, &#39;http&#39;, &#39;post&#39;, &#39;read&#39;, &#39;blogs&#39;, &#39;comments&#39;, &#39;blogger&#39;, &#39;name&#39;, &#39;link&#39;, &#39;page&#39;, &#39;write&#39;, &#39;list&#39;]

Topic number: 98, 149.390000000175
[]

Topic number: 99, 5478.585012047613
[&#39;bus&#39;, &#39;students&#39;, &#39;lisa&#39;, &#39;drivers&#39;, &#39;high&#39;, &#39;poetry&#39;, &#39;employees&#39;, &#39;employee&#39;, &#39;tub&#39;, &#39;workers&#39;, &#39;buses&#39;, &#39;phoenix&#39;, &#39;overtime&#39;, &#39;madness&#39;, &#39;eric&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="id11">
<h4>2.3<a class="headerlink" href="#id11" title="Link to this heading">#</a></h4>
<p>rubric={raw:2}</p>
<p>Next, pick an appropriate topic label for those topics from the list you just created that you judge to be a “good” topic. Look for topics where you can identify a clear theme in their words (it is okay if there a few words that don’t make sense - remember, this is still unsupervised!), and where the sum of psuedocounts is fairly high but not too high (There are always a few “kitchen sink” garbage topics). You should create a dictionary which maps from the label to the index: e.g.</p>
<p><code class="docutils literal notranslate"><span class="pre">topic_dict</span> <span class="pre">=</span> <span class="pre">{&quot;animals&quot;:0,</span> <span class="pre">&quot;geography&quot;:1,</span> <span class="pre">...}</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Your code here to make your dict &quot;manually&quot;</span>

<span class="c1"># Manually selected topic labels based on the earlier analysis</span>
<span class="n">topic_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># Social and personal life</span>
    <span class="s2">&quot;daily_life&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>            <span class="c1"># Words about daily activities and time (e.g., &#39;morning&#39;, &#39;week&#39;, &#39;hour&#39;)</span>
    <span class="s2">&quot;music&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>                 <span class="c1"># Words about music and bands (e.g., &#39;music&#39;, &#39;song&#39;, &#39;band&#39;)</span>
    <span class="s2">&quot;travel&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>                <span class="c1"># Words about travel and locations (e.g., &#39;beach&#39;, &#39;trip&#39;, &#39;hotel&#39;)</span>
    <span class="s2">&quot;home_and_decor&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>        <span class="c1"># Words about home and interior design (e.g., &#39;room&#39;, &#39;walls&#39;, &#39;paint&#39;)</span>

    <span class="c1"># Arts, culture, and media</span>
    <span class="s2">&quot;religion_and_beliefs&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="c1"># Words about religion and spirituality (e.g., &#39;god&#39;, &#39;church&#39;, &#39;faith&#39;)</span>
    <span class="s2">&quot;books_and_movies&quot;</span><span class="p">:</span> <span class="mi">14</span><span class="p">,</span>     <span class="c1"># Words about literature and films (e.g., &#39;movie&#39;, &#39;book&#39;, &#39;reading&#39;)</span>
    <span class="s2">&quot;art_and_photography&quot;</span><span class="p">:</span> <span class="mi">82</span><span class="p">,</span>  <span class="c1"># Words about creative arts and photography (e.g., &#39;art&#39;, &#39;camera&#39;, &#39;photos&#39;)</span>

    <span class="c1"># Sports and games</span>
    <span class="s2">&quot;sports&quot;</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>               <span class="c1"># Words about sports and games (e.g., &#39;game&#39;, &#39;team&#39;, &#39;match&#39;)</span>

    <span class="c1"># Food and drinks</span>
    <span class="s2">&quot;food&quot;</span><span class="p">:</span> <span class="mi">23</span><span class="p">,</span>                 <span class="c1"># Words about food and cooking (e.g., &#39;chicken&#39;, &#39;milk&#39;, &#39;bread&#39;)</span>

    <span class="c1"># Technology and the internet</span>
    <span class="s2">&quot;technology&quot;</span><span class="p">:</span> <span class="mi">17</span><span class="p">,</span>           <span class="c1"># Words about computers and the web (e.g., &#39;computer&#39;, &#39;internet&#39;, &#39;use&#39;)</span>

    <span class="c1"># Politics and society</span>
    <span class="s2">&quot;politics&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>             <span class="c1"># Words about politics and war (e.g., &#39;war&#39;, &#39;president&#39;, &#39;america&#39;)</span>
    <span class="s2">&quot;family_and_relationships&quot;</span><span class="p">:</span> <span class="mi">51</span><span class="p">,</span> <span class="c1"># Words about family life (e.g., &#39;dad&#39;, &#39;mom&#39;, &#39;kids&#39;)</span>
    <span class="s2">&quot;finance&quot;</span><span class="p">:</span> <span class="mi">84</span><span class="p">,</span>              <span class="c1"># Words about money and business (e.g., &#39;money&#39;, &#39;job&#39;, &#39;market&#39;)</span>

    <span class="c1"># Education</span>
    <span class="s2">&quot;education&quot;</span><span class="p">:</span> <span class="mi">99</span><span class="p">,</span>            <span class="c1"># Words about education and students (e.g., &#39;students&#39;, &#39;bus&#39;, &#39;drivers&#39;)</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id12">
<h4>2.4<a class="headerlink" href="#id12" title="Link to this heading">#</a></h4>
<p>rubric={accuracy:3,quality:1}</p>
<p>Build a retrieval system which takes a list of topics like <code class="docutils literal notranslate"><span class="pre">[&quot;technology&quot;,</span> <span class="pre">&quot;food&quot;]</span></code> (i.e. a query) and displays documents from your corpus which contain the desired set of topics.</p>
<p>Your (main) function should take a list of topics, and the number of top-ranked matches you want to see. You should only display texts whose topic proportions are 2 standard deviations above the topic proportion mean, that is, a z-score greater than 2 for all topics in the query. Your function should return the count of all texts which meet this bar in addition to the actual results.</p>
<p>The ranking of the displayed documents should be based on the z-score among the topics asked for, i.e. a higher z-score is better. When there are multiple topics in the same query, you should use the <em>lowest</em> z-score among the topic z-scores for comparison. E.g. let’s say the query contains the topics <code class="docutils literal notranslate"><span class="pre">[&quot;technology&quot;,</span> <span class="pre">&quot;food&quot;]</span></code>, and the z-score of <code class="docutils literal notranslate"><span class="pre">doc1</span></code> is 2.1 for <code class="docutils literal notranslate"><span class="pre">&quot;tecnhology&quot;</span></code> and 3.5 for <code class="docutils literal notranslate"><span class="pre">&quot;food&quot;</span></code>, and the z-score for <code class="docutils literal notranslate"><span class="pre">doc2</span></code> is 2.2 for <code class="docutils literal notranslate"><span class="pre">&quot;technology&quot;</span></code> and 2.3 for <code class="docutils literal notranslate"><span class="pre">&quot;food&quot;</span></code>. Then, <code class="docutils literal notranslate"><span class="pre">doc2</span></code> should be ranked higher in the results.</p>
<p>Print out a few examples that show that your retreival system is working, including at least one case with multiple topics.</p>
<p><strong>Hint:</strong> <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.zscore.html">scipy.stats.zscore</a>, note that you should specify the axis or flatten your data into a 1-dimensional array.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">zscore</span>
<span class="c1"># A z-score measures exactly how many standard deviations above or below the mean a data point is.</span>

<span class="n">MIN_Z_SCORE</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># your code here</span>
<span class="k">def</span> <span class="nf">get_topics</span><span class="p">(</span><span class="n">post_X</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">topic_list</span><span class="p">,</span> <span class="n">n_texts</span><span class="p">,</span> <span class="n">topic_dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Retrieve documents matching the given topics.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - post_X: Document-topic matrix (output of LDA.transform).</span>
<span class="sd">    - data: Original document texts (list of strings).</span>
<span class="sd">    - topic_list: List of topic labels to search for.</span>
<span class="sd">    - n_texts: Number of top-ranked matches to display.</span>
<span class="sd">    - topic_dict: Dictionary mapping topic labels to topic indices.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - Total count of matching documents.</span>
<span class="sd">    - List of top `n_texts` matching documents.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Get the topic indices for the query</span>
    <span class="n">topic_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">topic_dict</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">topic_list</span><span class="p">]</span>

    <span class="c1"># Transform the document matrix to topic proportions</span>
    <span class="n">topic_proportions</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">post_X</span><span class="p">)</span>

    <span class="c1"># Calculate z-scores for each topic</span>
    <span class="n">zscores</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">topic_proportions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">matches</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># List to store matches (min z-score, document)</span>

    <span class="k">for</span> <span class="n">post</span><span class="p">,</span> <span class="n">doc_zscores</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">zscores</span><span class="p">):</span>
        <span class="c1"># Check if all query topics have z-scores &gt;= MIN_Z_SCORE</span>
        <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">doc_zscores</span><span class="p">[</span><span class="n">topic_idx</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">MIN_Z_SCORE</span> <span class="k">for</span> <span class="n">topic_idx</span> <span class="ow">in</span> <span class="n">topic_indices</span><span class="p">):</span>
            <span class="c1"># Use the lowest z-score among the query topics for ranking</span>
            <span class="n">min_zscore</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">doc_zscores</span><span class="p">[</span><span class="n">topic_idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">topic_idx</span> <span class="ow">in</span> <span class="n">topic_indices</span><span class="p">)</span>
            <span class="n">matches</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">min_zscore</span><span class="p">,</span> <span class="n">post</span><span class="p">))</span>

    <span class="c1"># Sort matches by the minimum z-score in descending order</span>
    <span class="n">matches</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># Return total count and top `n_texts` matches</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">matches</span><span class="p">),</span> <span class="p">[</span><span class="n">match</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">[:</span><span class="n">n_texts</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_topics</span><span class="p">(</span><span class="n">post_X</span><span class="p">,</span> <span class="n">posts</span><span class="p">,</span> <span class="s2">&quot;food technology&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(),</span> <span class="mi">3</span><span class="p">,</span> <span class="n">topic_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1,
 [&quot;\r\n\r\n\t \r\n      The loonies in Kulitibank have been trying to pry my PHMNL password from me for weeks since I resigned. I have no idea what PHMNL means but giving access to it is practically like handing over a gun to someone who wants to assassinate me.   Why they want to get it is beyond me. The only thing remotely related to incriminating evidence they will find in my corporate email inbox are my work-related angsts, my pictures and my MP3s. Name one person in Kulitibank who doesn�t have any of the three in his PC and I will gladly write William Hung�s name using my butt.    Operation: Get Password  was carried out by Cruella de Ville, Oilve Oyl&#39;s sneaky and manipulative sidekick. Cruella is officially the �Junior IC� (a.k.a.  alalay ) but more often than not, she�s Olive Oyl�s hatchet woman.    Attempt No. 1  (On my cellphone)  Cruella: Heeeey, you know what, I can�t access the files in the laptop you surrendered�  Glenville: Naturally, Cruella. That�s because you don�t have my password.  Cruella: Yah, I know. But I just wanted to delete your files like what I did for Rose when she resigned.  Para clean siya .  Glenville: You can have it reformatted by the IT people. Everything�s gonna be wiped out.  Cruella: But�  Glenville: At this point, I really don�t want to give anyone my password. I am accountable for it and giving it to another employee is tantamount to violating the policy that I am not supposed to let anyone know of my password. (Capiche? Besides, I know who sent you. Go back to kissing Olive Oyl�s ass!)  Cruella: Ok.   Attempt No. 2  (A week later)  Cruella: Hi there! The IT guys can�t crack the PHMNL access. They can�t reformat your laptop either.  Glenville: Really? What if I forgot my password, then the laptop is useless? The IT people have administrator functions. They should be able to access and reformat my laptop even without my password. I guess the IT guys should be working as call center agents� (I am not a techie but I am not a dum-dum either)  Cruella: Oh, ok.   Attempt No. 3  (The truth unravels�)  Cruella calls me up on a Sunday evening warning me of Olive Oyl�s evil intentions  kuno .  Cruella: Hello, I just wanted to warn you.  Glenville: Warn me of what? (That your brain cells are actually working?)  Cruella: No, it�s just that I think Olive Oyl wants to snoop around your files. She told me that she wanted to look for something she can pin you down with.  Glenville: But why? I resigned already. Isn�t she happy?  Cruella: I think she wants to cover her tracks.  Glenville: Because she�s in a hot seat?  Cruella: I guess so. Three new hirees have resigned for the past 6 months, including you. A senior IC asked to be transferred to another department and another semi-senior IC has just resigned to join another bank. I think she can justify the others� moves but not yours. So she�s looking for a justifiable reason for your resignation in your files.  Glenville: Oh, I see. She wants to look for something she can blame me with so that it will look like her hands are totally clean.  Cruella: You should really give me your password so that I can delete your files before Olive Oyl gets to them. I really want to help you. (Warning bells! It�s not really in Cruella�s nature to help)  Glenville: No, thanks. I have nothing to hide anyway. Let Olive Oyl try to access my files. I think I even forgot what my password was already.  Cruella: You sure about that?  Glenville: Yep, thanks anyway.  For the record, all my files have been deleted, purged, emptied. I never told Cruella because I wanted her and Olive Oyl to go nuts trying to find a way to get my password. In the meantime, I am getting gas at holding in my laughter. Loonies.  \r\n     \r\n    \r\n&quot;])
</pre></div>
</div>
</div>
</div>
</section>
<section id="id13">
<h4>2.5 (Optional)<a class="headerlink" href="#id13" title="Link to this heading">#</a></h4>
<p>rubric={accuracy:1}</p>
<p>Modify your code above to print out the top 5 ranked words for each topic in the query for each result, and rerun your examples.</p>
<p><strong>Hint:</strong> the CountVectorizer that you built in Part 0 will be needed here, because you can use it to translate feature index numbers into words.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id14">
<h4>2.6 (Optional)<a class="headerlink" href="#id14" title="Link to this heading">#</a></h4>
<p>rubric={reasoning:1}</p>
<p>Play around with your topic search engine using a diversity of topic combinations, and print out two results lists that you find which have at least one correct and one incorrect result (incorrect meaning that at least one of the topics cannot be applied properly to the passage). Explain why you think the incorrect results happened, with reference to the limitations of the LDA model or perhaps errors in your topic naming.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">topic_dict</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="exercise-3-report">
<h3>Exercise 3: Report<a class="headerlink" href="#exercise-3-report" title="Link to this heading">#</a></h3>
<p>rubric={reasoning:3, writing:1}</p>
<p>After you have finished your lab, look back, and determine which methods were most successful, and which were not.  Does one method take more time than another?  Does one take more tuning of hyperparameters?  Is it worth the extra time / effort?  Write at least 2 paragraphs describing how these unsupervised methods compare with the supervised methods you’ve seen in your other classes. Finally, think about how you might be able to incorporate semi-supervised learning into topic-modeling.  It doesn’t have to be state-of-the-art - I just want you to think about how you might go about it.</p>
<p>Furthermore, as always, report which members of the team were responsible for which sections of the lab.  Did you do team coding, or did you assign certain parts of the lab to each other?  How did you arrive at this decision?</p>
<p><strong>Answer:</strong></p>
<p>This lab explored topic modeling and cluster analysis of text data through unsupervised learning methods such as K-means and LDA. The K-means method is efficient and suitable for quickly exploring data distribution, but it is sensitive to initial parameters and requires dimensionality reduction to improve the performance of high-dimensional data; although LDA topic modeling takes a long time to train and requires more hyperparameter adjustments, it can generate more semantically interpretable topics and is suitable for text analysis tasks. Compared with supervised methods, unsupervised methods do not require labels but the results are more difficult to verify. They are suitable for exploring unknown patterns or providing inspiration for supervised learning. In the future, the model effect can be further improved by combining semi-supervised learning (such as introducing some known labels), reducing the cost of parameter adjustment and training while improving the accuracy of topic modeling.</p>
<p>I (Yi) and Lingsong worked together this lab. Lingsong mainly responsible for the first part while I mainly responsible for the second part. After each one of us finished our own part, we firstly go through our code and logic of solving questions to the each other. This guaranteed each of us fully comprehend the whole lab. After we done each part, we push to our own branch and let the other one to confirm the pull request on github.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./archive"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="coronary-heart-disease-study.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Coronary Heart Disease Study</p>
      </div>
    </a>
    <a class="right-next"
       href="cfg-parsers.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">CFG Parsers</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assignment-objectives">Assignment Objectives</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-does-this-relate-to-what-we-re-doing-in-class">How does this relate to what we’re doing in class?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-started">Getting Started</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tidy-submission">Tidy Submission</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-0-prepare-the-corpus">Part 0: Prepare the corpus</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#assignment-0-1">Assignment 0.1</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-clustering-with-dimensionality-reduced-vectors">Part 1: Clustering with dimensionality reduced vectors</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">1.1</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">1.2</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">1.3</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#optional">1.4 (Optional)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">1.5 (Optional)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">1.6</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">1.7</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">1.8</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">1.9</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-topic-modelling">Part 2: Topic modelling</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">2.1</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">2.2</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">2.3</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">2.4</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">2.5 (Optional)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">2.6 (Optional)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-report">Exercise 3: Report</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Arno Zeng
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>